# DB Version: 14
# OS Type: linux
# DB Type: web
# Total Memory (RAM): 32 GB
# CPUs num: 4
# Data Storage: hdd

listen_addresses = '*'

max_connections = 200
shared_buffers = 8GB
effective_cache_size = 24GB
maintenance_work_mem = 2GB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 4
effective_io_concurrency = 2
work_mem = 20971kB
min_wal_size = 1GB
max_wal_size = 4GB
max_worker_processes = 4
max_parallel_workers_per_gather = 2
max_parallel_workers = 4
max_parallel_maintenance_workers = 2

archive_mode = on
archive_command = 's3cmd put %p s3://backups/wals/%f --access_key=$S3_ACCESS_KEY --secret_key=$S3_SECRET_KEY --host-bucket=recario-space.ams3.digitaloceanspaces.com --host=ams3.digitaloceanspaces.com --region=ams3 --no-check-certificate'
restore_command = 's3cmd get s3://backups/wals/%f %p --access_key=$S3_ACCESS_KEY --secret_key=$S3_SECRET_KEY --host-bucket=recario-space.ams3.digitaloceanspaces.com --host=ams3.digitaloceanspaces.com --region=ams3 --no-check-certificate'
wal_level = logical
wal_log_hints = on
max_wal_senders = 8
max_wal_size = 1GB
